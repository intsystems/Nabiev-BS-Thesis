{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch \n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import zlib\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize, basinhopping\n",
    "from sklearn.datasets import make_circles\n",
    "from tqdm.notebook import tqdm\n",
    "import operator\n",
    "from scipy.special import digamma\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "\n",
    "import sys \n",
    "sys.path.append('/home/bukkacha/Desktop/Inductive bias')\n",
    "from src.symreg import evaluate_composition, evaluate_tree, SymReg, Node, Composition, get_node_depth, DEFAULT_OPERATIONS\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_pattern(sequence, pattern):\n",
    "    pattern_str = ''.join(map(str, pattern))\n",
    "    sequence_str = ''.join(map(str, sequence))\n",
    "    return pattern_str in sequence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tasks = []\n",
    "all_nums = []\n",
    "for i in range(16):\n",
    "    all_nums.append(list(map(int, np.binary_repr(i, 4))))\n",
    "all_nums = np.array(all_nums)\n",
    "for i in range(8):\n",
    "    y_tasks.append([])\n",
    "    pattern = np.binary_repr(i)\n",
    "    pattern = pattern.rjust(3, '0')\n",
    "    pattern = list(map(int, list(pattern)))\n",
    "    if not i in [0, 7]: #i % 2 == 0:\n",
    "        for y in all_nums:\n",
    "            y_tasks[-1].append(int(contains_pattern(y, pattern)))\n",
    "    else:\n",
    "        for y in all_nums:\n",
    "            y_tasks[-1].append(int(contains_pattern(y[:3], pattern)) + int(contains_pattern(y[1:], pattern)))\n",
    "    \n",
    "all_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tasks = np.array(y_tasks)\n",
    "y_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(42)\n",
    "new_x, new_y = [], []\n",
    "for i in range(1, 7):\n",
    "    \n",
    "    y_ids = list(range(len(all_nums)))\n",
    "    while y_tasks[i][y_ids].mean() != 0.5:\n",
    "        if y_tasks[i][y_ids].mean()>0.5:\n",
    "            to_add = [j for j in range(len(all_nums)) if y_tasks[i][j] == 0]\n",
    "        else:\n",
    "            to_add = [j for j in range(len(all_nums)) if y_tasks[i][j] == 1]\n",
    "        to_add = rs.choice(to_add)\n",
    "        y_ids.append(to_add)\n",
    "    new_x.append(all_nums[y_ids])\n",
    "    new_y.append(y_tasks[i][y_ids])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "rs = np.random.RandomState(42)\n",
    "for i in [0, 7]:\n",
    "    y_ids = list(range(len(all_nums)))\n",
    "    cnt0 = (y_tasks[i][y_ids]==0).sum()\n",
    "    cnt1 =  (y_tasks[i][y_ids]==1).sum()\n",
    "    cnt2 =  (y_tasks[i][y_ids]==2).sum()\n",
    "\n",
    "    while (cnt0 != cnt1) or (cnt1 != cnt2):\n",
    "        to_add = np.argsort([cnt0, cnt1, cnt2])[0]\n",
    "        to_add = [j for j in range(len(all_nums)) if y_tasks[i][j] == to_add]\n",
    "        to_add = rs.choice(to_add)\n",
    "        y_ids.append(to_add)\n",
    "        cnt0 = (y_tasks[i][y_ids]==0).sum()\n",
    "        cnt1 = (y_tasks[i][y_ids]==1).sum()\n",
    "        cnt2 = (y_tasks[i][y_ids]==2).sum()\n",
    "\n",
    "\n",
    "    new_x.append(all_nums[y_ids])\n",
    "    new_y.append(y_tasks[i][y_ids])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 1, 1],\n",
       "        [1, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 0, 1, 1],\n",
       "        [1, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1]]),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [0, 0, 1, 0]]),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 0, 1, 1],\n",
       "        [0, 1, 1, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [1, 0, 1, 1]]),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0]]),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [1, 1, 0, 1],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 0, 1],\n",
       "        [1, 0, 1, 1]]),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 0, 1]]),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0]]),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 1, 0, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " array([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " array([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " array([2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 2, 1,\n",
       "        2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 1, 2, 1,\n",
       "        2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x, intens=1e-10):\n",
    "    # small noise to break degeneracy, see doc.\n",
    "    return x + intens * np.random.random_sample(x.shape)\n",
    "\n",
    "def build_tree(points):\n",
    "    if points.shape[1] >= 20:\n",
    "        return BallTree(points, metric='chebyshev')\n",
    "    return KDTree(points, metric='chebyshev')\n",
    "\n",
    "def count_neighbors(tree, x, r):\n",
    "    return tree.query_radius(x, r, count_only=True)\n",
    "\n",
    "def avgdigamma(points, dvec):\n",
    "    # This part finds number of neighbors in some radius in the marginal space\n",
    "    # returns expectation value of <psi(nx)>\n",
    "    tree = build_tree(points)\n",
    "    dvec = dvec - 1e-15\n",
    "    num_points = count_neighbors(tree, points, dvec)\n",
    "    return np.mean(digamma(num_points))\n",
    "\n",
    "def query_neighbors(tree, x, k):\n",
    "    return tree.query(x, k=k + 1)[0][:, k]\n",
    "\n",
    "def mi(x, y, z=None, k=3, base=2):\n",
    "    \"\"\" Mutual information of x and y (conditioned on z if z is not None)\n",
    "        x, y should be a list of vectors, e.g. x = [[1.3], [3.7], [5.1], [2.4]]\n",
    "        if x is a one-dimensional scalar and we have four samples\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y), \"Arrays should have same length\"\n",
    "    assert k <= len(x) - 1, \"Set k smaller than num. samples - 1\"\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    x, y = x.reshape(x.shape[0], -1), y.reshape(y.shape[0], -1)\n",
    "    x = add_noise(x) #add noise to both of x and y\n",
    "    y = add_noise(y)\n",
    "    points = [x, y]\n",
    "    if z is not None:\n",
    "        z = np.asarray(z)\n",
    "        z = z.reshape(z.shape[0], -1)\n",
    "        points.append(z)\n",
    "    points = np.hstack(points)\n",
    "    # Find nearest neighbors in joint space, p=inf means max-norm\n",
    "    tree = build_tree(points)\n",
    "    dvec = query_neighbors(tree, points, k)\n",
    "    if z is None:\n",
    "        a, b, c, d = avgdigamma(x, dvec), avgdigamma(\n",
    "            y, dvec), digamma(k), digamma(len(x))\n",
    "    else:\n",
    "        xz = np.c_[x, z]\n",
    "        yz = np.c_[y, z]\n",
    "        a, b, c, d = avgdigamma(xz, dvec), avgdigamma(\n",
    "            yz, dvec), avgdigamma(z, dvec), digamma(k)\n",
    "    return (-a - b + c + d) / np.log(base)\n",
    "\n",
    "def mymi(x1, x2):\n",
    "    x1 = np.array(x1)\n",
    "    x1 = (x1-x1.mean(0))/(1e-10+x1.std(0))\n",
    "    x2 = np.array(x2)\n",
    "    x2 = (x2-x2.mean(0))/(1e-10+x2.std(0))\n",
    "    return mi.mi(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import defaultdict, Counter\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value, children=None):\n",
    "        self.value = value\n",
    "        self.children = children or []\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.is_leaf():\n",
    "            return str(self.value)\n",
    "        return f\"{self.value}(\" + \", \".join(map(str, self.children)) + \")\"\n",
    "\n",
    "    def polish(self, ops):\n",
    "        operations = {}\n",
    "        alphabet = 'ABCDEFGHIJKLMOQRSTUVWYZ'\n",
    "        for k in ops:\n",
    "            operations[k] = alphabet[len(operations)]\n",
    "        if self.is_leaf():\n",
    "            if self.value.startswith('p'):\n",
    "                return 'P'\n",
    "            else:\n",
    "                return 'X'\n",
    "        return f\"{operations[self.value]}\" + \",\".join(\n",
    "            map(partial(Node.polish, ops=ops), self.children))\n",
    "\n",
    "    def copy(self):\n",
    "        return deepcopy(self)\n",
    "\n",
    "def get_all_polish(children):\n",
    "    elements = []\n",
    "    for root in children:\n",
    "        buf = [root]\n",
    "        while len(buf)>0:\n",
    "            element = buf.pop()\n",
    "            elements.append(element.polish(DEFAULT_OPERATIONS))\n",
    "            buf.extend(element.children)\n",
    "    return Counter(elements)\n",
    "        \n",
    "\n",
    "def huffman_coding_length(counter):\n",
    "    heap = [[freq, [sym, \"\"]] for sym, freq in counter.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    if len(heap) == 1:\n",
    "        return list(counter.values())[0]\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        lo = heapq.heappop(heap)\n",
    "        hi = heapq.heappop(heap)\n",
    "        for pair in lo[1:]:\n",
    "            pair[1] = \"0\" + pair[1]\n",
    "        for pair in hi[1:]:\n",
    "            pair[1] = \"1\" + pair[1]\n",
    "        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
    "\n",
    "    huff_dict = {sym: code for freq, *rest in heap for sym, code in rest}\n",
    "    total_bits = sum(len(huff_dict[sym]) * freq for sym, freq in counter.items())\n",
    "    return total_bits\n",
    "\n",
    "def compute_huffman_compression_score(root):\n",
    "    counter = get_all_polish(root)\n",
    "    \n",
    "\n",
    "    huffman_bits = huffman_coding_length(counter)\n",
    "    return huffman_bits\n",
    "\n",
    "x1 = Node('x0')\n",
    "x2 = Node('x1')\n",
    "x3 = Node('x2')\n",
    "x4 = Node('x3')\n",
    "p0 = Node('p0')\n",
    "p1 = Node('p1')\n",
    "p2 = Node('p2')\n",
    "p3 = Node('p3')\n",
    "p4 = Node('p4')\n",
    "p5 = Node('p5')\n",
    "p6 = Node('p6')\n",
    "p7 = Node('p7')\n",
    "p8 = Node('p8')\n",
    "\n",
    "h10 = Node('mult', [p0, x1])\n",
    "h11 = Node('mult', [p1, x2])\n",
    "h12 = Node('mult', [p2, x3])\n",
    "\n",
    "h20 = Node('mult', [p0, x2])\n",
    "h21 = Node('mult', [p1, x3])\n",
    "h22 = Node('mult', [p2, x4])\n",
    "\n",
    "h1 = Node('add', [p3, Node('add', [h10, Node('add', [h11, h12])])])\n",
    "h2 = Node('add', [p4, Node('add', [h20, Node('add', [h21, h22])])])\n",
    "\n",
    "h1_ = Node('h0')\n",
    "h2_ = Node('h1')\n",
    "\n",
    "g0_max = Node('max', [h1_, h2_])\n",
    "g0 = Node('add', [g0_max, p5])\n",
    "\n",
    "\n",
    "\n",
    "h111 = Node('max', [h1_, p5])\n",
    "\n",
    "h222 = Node('max', [h2_, p5])\n",
    "g1 = h222\n",
    "g1 = Node('add', [h111, h222])\n",
    "g0 = g0\n",
    "comp = Composition([h1, h2], [g0, g1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_node_depth(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(evaluate_composition(comp, {f'x{i}':new_x[7][:, i] for i in range(4)}, {'p0':1, 'p1':1, 'p2': 1, 'p3':-2,\n",
    "                                                                 'p4': -2.0, 'p5': -0.0},\n",
    "                     DEFAULT_OPERATIONS, g_id=1), new_y[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h_0 = add(p3, add(mult(p0, x0), add(mult(p1, x1), mult(p2, x2))))\n",
      "h_1 = add(p4, add(mult(p0, x1), add(mult(p1, x2), mult(p2, x3))))\n",
      "g_0 = add(max(h0, h1), p5)\n",
      "g_1 = add(max(h0, p5), max(h1, p5))\n"
     ]
    }
   ],
   "source": [
    "print (comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brute, basinhopping, minimize\n",
    "from functools import partial\n",
    "from symreg import evaluate_composition, DEFAULT_OPERATIONS\n",
    "\n",
    "import zlib\n",
    "\n",
    "\n",
    "def compress_score(expression_str: str):\n",
    "    compressed = zlib.compress(expression_str.encode('utf-8'))\n",
    "    return len(compressed)\n",
    "\n",
    "\n",
    "def compress_hiddens(composition):\n",
    "    return compress_score(';'.join([\n",
    "        h.polish(DEFAULT_OPERATIONS) for h in composition.children_h]))\n",
    "\n",
    "def acc_loss_fn_min(x, y, ind, variables, pool, OPERATIONS):\n",
    "    bad_val = [9999] * (1 + 2 +8)\n",
    "    multistart_num = 20\n",
    "    param_num = len(pool)\n",
    "    losses = [0.0]\n",
    "    \n",
    "    compl = compute_huffman_compression_score(ind.children_h)\n",
    "    if compl > 62:\n",
    "        return bad_val\n",
    "    \n",
    "    losses.append(compl)\n",
    "    losses.append(0.0) # MI\n",
    "    \n",
    "    losses[0] += losses[-1]\n",
    "    \n",
    "    def min_func(x0, var_y, debug = False):\n",
    "        var_, y_ = var_y\n",
    "        pool_ = {f'p{i}': x0[i] for i in range(param_num)}\n",
    "        y_pred = evaluate_composition(ind, var_, pool_, OPERATIONS) > 0\n",
    "        errs = 1.0-np.equal(y_, y_pred).mean()\n",
    "        return errs\n",
    "    \n",
    "    def min_func2(x0, var_y):\n",
    "        var_, y_ = var_y\n",
    "        pool_ = {f'p{i}': x0[i] for i in range(len(x0))}\n",
    "        y_pred = evaluate_composition(ind, var_, pool_, OPERATIONS, g_id=1)\n",
    "        y_pred = np.clip(y_pred, 0, 2)\n",
    "        errs = ((y_ - y_pred)**2).mean() / 2\n",
    "        return errs\n",
    "    \n",
    "    for i in range(6):\n",
    "        x_train1 = {f'x{j}': new_x[i][:, j] for j in range(4)}\n",
    "        y_train1 = new_y[i]\n",
    "        best = None, None\n",
    "        #print ('--')\n",
    "        for _ in range(multistart_num):\n",
    "            x_opt = minimize(partial(min_func, var_y = [x_train1, y_train1]),  np.random.uniform(-3, 3, size=param_num), \n",
    "                             options = {'maxiter': 10000},\n",
    "                             method='Powell', bounds=[(-3.0, 3.0)]*param_num) #,  [(-3, 3)]*param_num, Ns=20)\n",
    "            if best[1] is None or best[1]>x_opt.fun:\n",
    "                best = x_opt, x_opt.fun\n",
    "                #print ('*')\n",
    "                if best[1] == 0.0:\n",
    "                    break\n",
    "        x_opt = best[0]\n",
    "        losses.append(min_func(x_opt.x, [x_train1, y_train1]))\n",
    "        losses[0] += losses[-1]\n",
    "        \n",
    "        hidden1, out1 = evaluate_composition(ind, x_train1, {f'p{i}': x_opt.x[i] for i in range(param_num)}, \n",
    "                                             OPERATIONS, 0, True)\n",
    "        hidden1_array = []\n",
    "        for h in hidden1.values():\n",
    "            h = np.array(h)\n",
    "            if len(h.shape) == 0:\n",
    "                h = np.ones(len(y_train1) )* h\n",
    "                \n",
    "            hidden1_array.append(h)\n",
    "        hidden1_array = np.array(hidden1_array).T\n",
    "        losses[2] += mymi(hidden1_array, np.array(list(x_train1.values())).T)\n",
    "        \n",
    "    \n",
    "    for i in range(6, 8):\n",
    "        x_train2 = {f'x{j}': new_x[i][:, j] for j in range(4)}\n",
    "        y_train2 = new_y[i]\n",
    "        best = None, None\n",
    "        for _ in range(multistart_num):\n",
    "            x_opt = minimize(partial(min_func2, var_y = [x_train2, y_train2]),\n",
    "                             np.random.uniform(-3, 3, size=param_num), \n",
    "                             options = {'maxiter': 10000},\n",
    "                             method='Powell', bounds=[(-3.0, 3.0)]*param_num) #,  [(-3, 3)]*param_num, Ns=20)\n",
    "            if best[1] is None or best[1]>x_opt.fun:\n",
    "                best = x_opt, x_opt.fun\n",
    "                #print ('*')\n",
    "                if best[1] == 0.0:\n",
    "                    break\n",
    "        x_opt = best[0]\n",
    "        \n",
    "        losses.append(min_func2(x_opt.x, [x_train2, y_train2]))\n",
    "        losses[0] += losses[-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        hidden1, out1 = evaluate_composition(ind, x_train2, {f'p{i}': x_opt.x[i] for i in range(param_num)}, \n",
    "                                             OPERATIONS, 0, True)\n",
    "        hidden1_array = []\n",
    "        for h in hidden1.values():\n",
    "            h = np.array(h)\n",
    "            if len(h.shape) == 0:\n",
    "                h = np.ones(len(y_train2) )* h\n",
    "                \n",
    "            hidden1_array.append(h)\n",
    "        hidden1_array = np.array(hidden1_array).T\n",
    "        losses[2] += mymi(hidden1_array, np.array(list(x_train2.values())).T)\n",
    "        \n",
    "    if losses[2] >= 10.2:\n",
    "        return bad_val\n",
    "    losses[0] += (losses[1]/62)*0.1\n",
    "    losses[0] += (losses[2]/10.2)*0.1\n",
    "    \n",
    "    \n",
    "    return tuple(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gen 0] Expr: \n",
      "h_0 = max(x1, p2)\n",
      "h_1 = x2\n",
      "g_0 = mult(sub(sub(max(p5, h0), max(p1, p0)), sub(mult(h1, h0), max(h1, h0))), add(max(mult(h1, h1), add(p4, h1)), add(h0, mult(p4, p1))))\n",
      "g_1 = mult(h0, sub(mult(h1, p3), sub(p0, p1)))\n",
      "[Gen 0] Best errors: (np.float64(1.908252118743698), 6.0, np.float64(8.482576326910939), np.float64(0.33333333333333337), np.float64(0.16666666666666663), np.float64(0.33333333333333337), np.float64(0.16666666666666663), np.float64(0.16666666666666663), np.float64(0.33333333333333337), np.float64(0.20430107526881716), np.float64(0.11111111111111108))\n",
      "[Gen 0] Total time: 164.4539704322815\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import operator\n",
    "reduced_operations = {\n",
    "    'add': (operator.add, 2),\n",
    "    'sub': (operator.sub, 2),\n",
    "    'mult': (operator.mul, 2),\n",
    "    'max': (np.maximum, 2)\n",
    "}\n",
    "np.random.seed(42)\n",
    "import time\n",
    "time_s = time.time()\n",
    "run_num = 5\n",
    "gens = []\n",
    "for r in range(run_num):\n",
    "    symreg = SymReg(acc_loss_fn_min,\n",
    "                    new_x[0],\n",
    "                    new_y[0],\n",
    "                    10,\n",
    "                    2,\n",
    "                    2,\n",
    "                    6,\n",
    "                    1000,\n",
    "                    proc_num = 8,\n",
    "                    operations=reduced_operations,\n",
    "                    mutate_params=False,\n",
    "                    max_depth=4)\n",
    "    gens.append(symreg.fit(50, 10, 10, 10))\n",
    "    with open('results_exp5.pckl', 'wb') as out:\n",
    "        out.write(pickle.dumps(gens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.175      0.11328329 0.         0.         0.         0.        ] [0.08333333 0.04253008 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "qual = []\n",
    "for f in gens:\n",
    "    qual.append(f.fitness.getValues()[1:])\n",
    "print (np.mean(qual,0), np.min(qual, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train1 = {f'x{i}':X_all[:24,i] for i in range(4)}\n",
    "y_train1 = y_all[:24]\n",
    "\n",
    "def min_func(x0, var_y):\n",
    "    var_, y_ = var_y\n",
    "    pool_ = {f'p{i}': x0[i] for i in range(len(x0))}\n",
    "    y_pred = evaluate_composition(comp, var_, pool_, DEFAULT_OPERATIONS) > 0\n",
    "    errs = 1.0-np.equal(y_, y_pred).mean()\n",
    "    \n",
    "    return errs\n",
    "\n",
    "x_opt = basinhopping(partial(min_func, var_y = [x_train1, y_train1]),  [-0.0, -0.0])\n",
    "loss1 = min_func(x_opt.x, [x_train1, y_train1])\n",
    "loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.equal(np.round(evaluate_composition(comp, {f'x{i}':X_all[:24,i] for i in range(4)}, {'p0':  -1.0}, DEFAULT_OPERATIONS)) > 0, y_all[:24])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all[:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mi(h, y):\n",
    "    mi = 0.0\n",
    "    for _ in range(100):\n",
    "        P = np.random.randn(h.shape[1], 1)\n",
    "\n",
    "        cov_matrix = np.cov(h @ P, y.reshape(-1, 1).T, rowvar=False)\n",
    "        mi += cov_matrix[0, 1]**2\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7d06b8239210>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = np.zeros((6, 6))\n",
    "i = np.unravel_index([12, 15, 22, 24, 35], [6, 6])\n",
    "mat[i] = 1\n",
    "plt.matshow(mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InductiveBias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
